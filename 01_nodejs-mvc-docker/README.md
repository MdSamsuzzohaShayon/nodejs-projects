*Tutorial* __https://www.youtube.com/watch?v=XlvsJLer_No&list=PLZlA0Gpn_vH8jbFkBjOuFjhxANC63OmXM&index=1__


# Heroku setup 

 1. Create new app

  ![](/screenshots/1.png)

 2. Set an app name that is available

  ![](/screenshots/2.png)

 3. Choose any deployment method you like (Here I will use Heroku cli)
   - download heroku cli and install is and 
   - use those following commands 

  ![](/screenshots/3.png)

 4. Go to app setting setup variable that we made in .env file in our project

  ![](/screenshots/4.png)

 5. setup for mongodb variable 
   - the key from .env file in our project
   - value is from mongodb atlas or mlab or any other cloud that deply db and running globally

  ![](/screenshots/5.png)

*Now open the app*


### File Management

 - There are few ways to upload file. 
 - In heroku file system when we upload our files and restart heroku server files will delete automitacally
 - **Best Solution** is to upload this files to a seperate file server such as Amazon s3 or any other file storage system (All are paid)
 - Another easy way is to store file in database that is not ideal but it's free to play around with

 - **[Filepond](https://pqina.nl/filepond/)** A JavaScript library that can upload anything you throw at it, optimizes images for faster uploads, and offers a great, accessible, silky smooth user experience.
 [Github](https://github.com/pqina/filepond)


### Docker
 - Stop running on localhost machine 
 - Build docker image `sudo docker build .`
 - See all docker image `sudo docker image ls`
  2004  sudo docker --version
 - List all containers `sudo docker ps -a`
 - Once **Dockerfile** is created build docker image `sudo docker build -t nodejs-bookshop .`
 - Remove all unused image `sudo docker image prune --all`
 - Remove a particular image `sudo docker image -rm -f image_id`
 - Remove all docker images `sudo docker system prune -a`
 - Build docker image with a name `sudo docker build -t nodejs-bookshop .`
 - Make our container with image `sudo docker run -p 3000:3000 -d --name name_of_container name_of_image` **p** means setting port **3000** on the left represent the port localmachine or internet try to access and the port **3000 on the right** the port that will be forwarded to the docker container
 - Docker logs `sudo docker logs 8f67f58f3eb4` - if everything is okay we can see our **apps on obrowser**
 - See the file systems of our container `sudo docker exec -it container_id_or_name bash` in interactive mode **it**
 - Before changing any code of nodejs project remove container `sudo docker rm name_of_container -f` build docker image once againa and run it
 - Volumes are the preferred mechanism for persisting data generated by and used by Docker containers. By using columes we can sync all files and folders from our local machine to our docker containers
 - Remove `sudo docker rm node-book -f` and run container once again `sudo docker run -v $(pwd):/app -p 3000:3000 -d --name node-book nodejs-bookshop-image` here **-v** stands for columes and **$(pwd)** means directory of our project folder. This will sync from our project folder to container **/app** folder. So everytime we change code we don't have to build our image.
 - delete **node_modules** folder from local project now this app won;t run `sudo docker run -v $(pwd):/app:ro -v /app/node_modules -p 3000:3000 -d --name node-book nodejs-bookshop-image` **-v /app/node_modules** this will prevent to delete node_modules folder when it sync all folders
 - **-v $(pwd):/app:ro** here ro stands for readonly that if we change any code from container that won't effect in our code from local project bucause that's read only.
 - Change environment variable from docker container ->  
    ```
    // remove docker container
    sudo docker rm node-book -f
    // set env variable in Dockerfile - since we change anything in Dockerfile we need to build the image once again
    // remove unused image
    sudo docker image prune
    // build image once again
    sudo docker build -t nodejs-bookshop-image .
    // run container
    sudo docker run -v $(pwd):/app:ro -v /app/node_modules --env-file ./config/.env  -p 3000:4000 -d --name node-book nodejs-bookshop-image
    // for loding or using .env file in our container we could use --env-file ./config/.env 
    // we con also set environemnt veriable from terminal using --env PORT=4000 in the place of --env-file ./config/.
    ```
 - Everytime we delete our container that preserve volume `sudo docker volume ls` to delete that unused volume `sudo docker volume prune`
 - Everytime when we delete use -fv `sudo docker rm node-book -fv` so it will delete volume along with container

#### Docker Compose
 - This is running only one container but when we will develop an application we will have multiple container (node.js, mongodb, redis, etc). To automate all those steps we have to use docker compose
 - [Create a docker compose file](https://docs.docker.com/compose/) - we are going to make same thing as run a container or create a container with all those flags. Insted of long command we can use docker compose
 - `sudo docker-compose up -d` this will build our image and run container as well. delete container `sudo docker-compose down -v`
 - force to recreate new image `sudo docker-compose up -d --build` and to delete `sudo docker-compose down -v`
 - Running docker for development `udo docker-compose -f docker-compose.yml -f docker-compose.dev.yml up -d --build` to remove it run `sudo docker-compose -f docker-compose.yml -f docker-compose.dev.yml down -v`
 - In production version we don't have any docker iignored file inside container run the command for production 
    ```
    sudo docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d --build
    sudo docker-compose -f docker-compose.yml -f docker-compose.prod.yml down -v
    ```